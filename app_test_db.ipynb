{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from htmldate import find_date\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "import openai\n",
    "import multiprocessing\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from html_extractor import *\n",
    "from get_suburls import *\n",
    "from openai_func import *\n",
    "from get_date import *\n",
    "from parallel import *\n",
    "from mongo_utils import import_from_mongo, save_to_mongo\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from keyword_extraction import keyword_extractor_paragraph as kep\n",
    "\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import certifi\n",
    "ca = certifi.where()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting sub urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.09s/it]\n",
      "100%|██████████| 67/67 [00:23<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Fetch: 0\n",
      "Splits: 4\n",
      "Tree size: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "urls_list = [\"https://www.khaleejtimes.com\" , \"https://www.indiatoday.in\"]\n",
    "urls_list_str = \",\".join(urls_list)\n",
    "\n",
    "keywords = \"gaza,israel,hamas,idf\"\n",
    "\n",
    "scraper = WebScraper2(sub_url_size = 3 , keywords = keywords)\n",
    "                        # Integration with DB will make it faster in future, as fetching is much faster than scrapping.\n",
    "inside_urls, failed_fetch, sub_url_size, total_size = scraper.get_suburls2(urls_list_str)\n",
    "\n",
    "# print(\"Inside URLs:\", inside_urls)\n",
    "print(\"Failed Fetch:\", failed_fetch)\n",
    "print(\"Splits:\", len(inside_urls))\n",
    "print(\"Tree size:\", total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining sub urls into one single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_urls = [item for sublist in list(inside_urls.values()) for item in sublist]\n",
    "len(website_urls)\n",
    "# print(len(website_urls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB integration for Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Date db from mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>https://www.indiatoday.in/undefined/world/stor...</td>\n",
       "      <td>2024-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>https://www.indiatoday.in/world/story/us-secre...</td>\n",
       "      <td>2024-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>https://www.indiatoday.in/undefined/world/stor...</td>\n",
       "      <td>2024-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>https://www.indiatoday.in/world/story/new-york...</td>\n",
       "      <td>2024-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>https://www.indiatoday.in/world/story/war-isra...</td>\n",
       "      <td>2024-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>https://www.indiatoday.in/world/story/rockets-...</td>\n",
       "      <td>2023-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.indiatoday.in/topic/israel</td>\n",
       "      <td>2019-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.indiatoday.in</td>\n",
       "      <td>2019-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>https://www.khaleejtimes.com/opinion/life-is-w...</td>\n",
       "      <td>2017-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>https://www.khaleejtimes.com/world/palestinian...</td>\n",
       "      <td>2015-04-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url       Date\n",
       "129  https://www.indiatoday.in/undefined/world/stor... 2024-01-09\n",
       "130  https://www.indiatoday.in/world/story/us-secre... 2024-01-09\n",
       "131  https://www.indiatoday.in/undefined/world/stor... 2024-01-09\n",
       "132  https://www.indiatoday.in/world/story/new-york... 2024-01-09\n",
       "128  https://www.indiatoday.in/world/story/war-isra... 2024-01-09\n",
       "..                                                 ...        ...\n",
       "108  https://www.indiatoday.in/world/story/rockets-... 2023-10-07\n",
       "1               https://www.indiatoday.in/topic/israel 2019-09-12\n",
       "12                           https://www.indiatoday.in 2019-09-12\n",
       "86   https://www.khaleejtimes.com/opinion/life-is-w... 2017-07-31\n",
       "122  https://www.khaleejtimes.com/world/palestinian... 2015-04-04\n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_db_name = \"PetraOil\"\n",
    "collection_db_name = \"Date Database\"\n",
    "columns = [\"url\", \"Date\"]\n",
    "mongo_date_df = import_from_mongo(date_db_name, collection_db_name, columns)\n",
    "mongo_date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urls of extracted sub urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.khaleejtimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.indiatoday.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.indiatoday.in/topic/israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.khaleejtimes.com/world/americas/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.khaleejtimes.com/long-reads/from-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>https://www.indiatoday.in/undefined/world/stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>https://www.indiatoday.in/world/video/israel-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>https://www.khaleejtimes.com/videos/palestine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>https://www.khaleejtimes.com/world/mena/if-i-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>https://www.indiatoday.in/world/story/rockets-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url\n",
       "0                         https://www.khaleejtimes.com\n",
       "1                            https://www.indiatoday.in\n",
       "2               https://www.indiatoday.in/topic/israel\n",
       "3    https://www.khaleejtimes.com/world/americas/lo...\n",
       "4    https://www.khaleejtimes.com/long-reads/from-i...\n",
       "..                                                 ...\n",
       "155  https://www.indiatoday.in/undefined/world/stor...\n",
       "156  https://www.indiatoday.in/world/video/israel-p...\n",
       "157  https://www.khaleejtimes.com/videos/palestine-...\n",
       "158  https://www.khaleejtimes.com/world/mena/if-i-m...\n",
       "159  https://www.indiatoday.in/world/story/rockets-...\n",
       "\n",
       "[160 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_from_extraction = pd.DataFrame(website_urls[:160]) \n",
    "urls_from_extraction.columns = [\"url\"]\n",
    "urls_from_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urls that arent yet indexed in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>https://www.indiatoday.in/world/story/street-c...</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>https://www.aa.com.tr/en/europe/irish-oppositi...</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url Date\n",
       "177  https://www.indiatoday.in/world/story/street-c...  NaT\n",
       "178  https://www.aa.com.tr/en/europe/irish-oppositi...  NaT"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_which_to_find_the_date_of = pd.merge(mongo_date_df, urls_from_extraction, how = \"outer\")\n",
    "df_of_which_to_find_the_date_of = df_of_which_to_find_the_date_of.loc[~df_of_which_to_find_the_date_of['Date'].notna(), :] # Dates that are yet found out\n",
    "df_of_which_to_find_the_date_of = df_of_which_to_find_the_date_of.drop_duplicates(subset='url', keep='first')              # Dropping duplicates if any\n",
    "df_of_which_to_find_the_date_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yet to index: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Yet to index: {df_of_which_to_find_the_date_of.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.indiatoday.in/world/story/street-combat-long-tunnels-how-hamas-aims-to-trap-israel-in-gaza-strip-2458085-2023-11-04',\n",
       " 'https://www.aa.com.tr/en/europe/irish-opposition-sinn-fein-reiterates-call-for-cease-fire-in-gaza/3052728']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_which_to_find_the_date_of = list(df_of_which_to_find_the_date_of[\"url\"].values)\n",
    "list_of_which_to_find_the_date_of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting dates for extracted urls that arent indexed in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "url_date_list = []\n",
    "timeout_seconds = 5\n",
    "\n",
    "for url in tqdm(list_of_which_to_find_the_date_of):\n",
    "    start_time = time()\n",
    "    try:\n",
    "        # Your function to fetch the date from the URL\n",
    "        date_value = fetch_date_from_url(url)\n",
    "    except Exception as e:\n",
    "        # Handle exceptions, e.g., print an error message or store a default value\n",
    "        print(f\"Error fetching date for {url}: {e}\")\n",
    "        date_value = None\n",
    "\n",
    "    elapsed_time = time() - start_time\n",
    "\n",
    "    # Append to the list if the operation took less than the timeout\n",
    "    if elapsed_time < timeout_seconds:\n",
    "        url_date_list.append([url, date_value])\n",
    "    else:\n",
    "        print(f\"Skipping {url} due to timeout of {timeout_seconds}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['https://www.indiatoday.in/world/story/street-combat-long-tunnels-how-hamas-aims-to-trap-israel-in-gaza-strip-2458085-2023-11-04',\n",
       "  '04-11-2023'],\n",
       " ['https://www.aa.com.tr/en/europe/irish-opposition-sinn-fein-reiterates-call-for-cease-fire-in-gaza/3052728',\n",
       "  None]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.indiatoday.in/world/story/street-combat-long-tunnels-how-hamas-aims-to-trap-israel-in-gaza-strip-2458085-2023-11-04': '04-11-2023',\n",
       " 'https://www.aa.com.tr/en/europe/irish-opposition-sinn-fein-reiterates-call-for-cease-fire-in-gaza/3052728': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_date_dict = {i[0] : i[1] for i in url_date_list}\n",
    "url_date_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted in Mongodb cloud\n",
      "Database: PetraOil\n",
      "Collection: Date Database\n"
     ]
    }
   ],
   "source": [
    "# Insert the document into the collection\n",
    "\n",
    "data = url_date_dict\n",
    "date_db_name = \"PetraOil\"\n",
    "collection_db_name = \"Date Database\"\n",
    "\n",
    "\n",
    "save_to_mongo(date_db_name, collection_db_name, data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating {url : html content} dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_html_extracted = get_html(website_urls)\n",
    "# url_html_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword extraction performed on above dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:00<00:00, 8663.04it/s]\n"
     ]
    }
   ],
   "source": [
    "url_extracted_html = kep(website_content = url_html_extracted[0], keywords = keywords, filter_by_amount = 60)\n",
    "\n",
    "# url_extracted_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dictionary to list of tuple pairs, for implementation of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = [(key,value[:2000]) for key, value in url_extracted_html.items()] # 1000 is temporary until tokenier function is not set up\n",
    "# content_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting the above list fo batches of batch size MAX_CONTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_CONTENT = 5\n",
    "\n",
    "content_list_complete = []\n",
    "\n",
    "iterations = len(content_list) // MAX_CONTENT\n",
    "\n",
    "\n",
    "for i in range(iterations):\n",
    "    sub_content_list = content_list[MAX_CONTENT * i: MAX_CONTENT * (i + 1)]\n",
    "    content_list_complete.append(sub_content_list)\n",
    "\n",
    "# Handle remaining elements after the loop\n",
    "remaining_elements = content_list[MAX_CONTENT * iterations:]\n",
    "if remaining_elements:\n",
    "    iterations += 1\n",
    "    content_list_complete.append(remaining_elements)\n",
    "\n",
    "len(content_list_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Openai's api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non parallel execution of 1 api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 out of 24 completed \n",
      "Batch 2 out of 24 completed \n",
      "Batch 3 out of 24 completed \n",
      "Batch 4 out of 24 completed \n",
      "Batch 5 out of 24 completed \n",
      "Batch 6 out of 24 completed \n",
      "Batch 7 out of 24 completed \n",
      "Batch 8 out of 24 completed \n",
      "Batch 9 out of 24 completed \n",
      "Batch 10 out of 24 completed \n",
      "Executed in 216.86s\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "start = time()\n",
    "\n",
    "question = \"Summary of situation in gaza\"\n",
    "\n",
    "response_complete = ''\n",
    "for data_idx in range(10):\n",
    "\n",
    "    prompt = f\"\"\" \n",
    "        Data is in the form of tuples inside list: {content_list_complete[data_idx]} \\n\\n\\n \n",
    "        Question: {question} \\n\\n\\n\n",
    "        Method of reply: 100 - 200 word sentences, clear reply,\n",
    "        provide url if neccessary.\n",
    "        \"\"\"\n",
    "    \n",
    "    if data_idx % 6 == 0:\n",
    "        sleep(20)\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    response_complete += response + \"\\n\\n\"\n",
    "    print(f\"Batch {data_idx + 1} out of {iterations} completed \")\n",
    "\n",
    "end = time()\n",
    "\n",
    "print(f\"Executed in {end-start:.2f}s\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution for 2 api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 - 2 executed out of 24\n",
      "Batch 3 - 4 executed out of 24\n",
      "Batch 5 - 6 executed out of 24\n",
      "Batch 7 - 8 executed out of 24\n",
      "Batch 9 - 10 executed out of 24\n",
      "Executed in 98.97s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "complete_result_of_openai = \"\"\n",
    "question_to_pass = \"status of war in gaza\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "NUM_OF_API = 2\n",
    "\n",
    "for i in range(0, 10, NUM_OF_API):\n",
    "\n",
    "    if count % 6 == 0:\n",
    "        sleep(20)\n",
    "    \n",
    "\n",
    "    result = ''\n",
    "\n",
    "    result_queue1 = multiprocessing.Queue()\n",
    "    result_queue2 = multiprocessing.Queue()\n",
    "\n",
    "\n",
    "    process1 = multiprocessing.Process(target=gpt1, args=(question_to_pass, content_list_complete, i, result_queue1))\n",
    "    process2 = multiprocessing.Process(target=gpt3, args=(question_to_pass, content_list_complete, i+1, result_queue2))\n",
    "\n",
    "\n",
    "    # Start processes\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "\n",
    "    # Wait for processes to finish\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "\n",
    "\n",
    "    result1 = result_queue1.get()\n",
    "    result2 = result_queue2.get()\n",
    "\n",
    "    # Rest of your code remains unchanged\n",
    "    result = result1 + \"\\n\\n\" + result2 + \"\\n\\n\"\n",
    "    complete_result_of_openai += result\n",
    "\n",
    "    print(f\"Batch {i+1} - {i+NUM_OF_API} executed out of {len(content_list_complete)}\")\n",
    "    count += 1\n",
    "complete_result_of_openai\n",
    "\n",
    "end = time()\n",
    "\n",
    "print(f\"Executed in {end-start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.204081632653061"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "216/98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = get_completion(f\"Provide Detailed Summary of {complete_result_of_openai}\")\n",
    "# response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Output_gaza_parallel.txt\" , \"w\") as f:\n",
    "    f.write(complete_result_of_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Output_gaza_parallel_summary.txt\" , \"w\") as f:\n",
    "    f.write(complete_result_of_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Output_gaza.txt\" , \"w\") as f:\n",
    "    f.write(response_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Output_gaza_summary.txt\" , \"w\") as f:\n",
    "    f.write(response2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
